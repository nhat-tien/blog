<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Nhat Tien</title><link>https://tienldn.online/tag/machine-learning/</link><description>Recent content in Machine Learning on Nhat Tien</description><generator>Hugo</generator><language>en</language><lastBuildDate>Mon, 25 Aug 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://tienldn.online/tag/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Tiền Xử Lí Dữ Liệu Trong Logistic Regression</title><link>https://tienldn.online/blog/xu-li-du-lieu-trong-logistic-regression/</link><pubDate>Mon, 25 Aug 2025 00:00:00 +0000</pubDate><guid>https://tienldn.online/blog/xu-li-du-lieu-trong-logistic-regression/</guid><description>&lt;h2 id="làm-sạch-dữ-liệu">Làm sạch dữ liệu 
 
 
&lt;/h2>
&lt;h2 id="biến-đổi-dữ-liệu">Biến đổi dữ liệu 
 
 
&lt;/h2>
&lt;h2 id="feature-engineering">Feature Engineering 
 
 
&lt;/h2>
&lt;h2 id="chia-nhỏ-và-đơn-giản-hóa-dữ-liệu">Chia nhỏ và đơn giản hóa dữ liệu 
 
 
&lt;/h2></description></item><item><title>Tối Ưu Hóa Hàm Mất Mát Trong Logistic Regression</title><link>https://tienldn.online/blog/toi-uu-hoa-ham-mat-mat/</link><pubDate>Sat, 23 Aug 2025 00:00:00 +0000</pubDate><guid>https://tienldn.online/blog/toi-uu-hoa-ham-mat-mat/</guid><description>&lt;h2 id="kỹ-thuật-gradient-descent">Kỹ thuật Gradient Descent 
 
 
&lt;/h2>
&lt;p>Gradient Descent là thuật toán tối ưu phổ biến trong máy học, dùng để tìm
điểm cực tiểu của loss function, hay nói cách khác là tìm điểm tham số tối ưu
để cho ra sai số nhỏ nhất.&lt;/p>
&lt;p>Công thức chung cho các dạng Gradient Descent là:&lt;/p>
$$
 \textbf{w}_{new} = \textbf{w}_{old} - \alpha \cdot \nabla J(\textbf{w})
$$&lt;p>Với:&lt;/p>
&lt;ul>
&lt;li>\(\textbf{w}\) : vector hệ số.&lt;/li>
&lt;li>\(\alpha\) : tốc độ học (learning rate).&lt;/li>
&lt;li>\(\nabla J(\textbf{w})\) : đạo hàm của loss function theo hệ số.&lt;/li>
&lt;/ul>
&lt;h2 id="đạo-hàm-của-loss-function">Đạo hàm của loss function 
 
 
&lt;/h2>
&lt;p>Ta có loss function tại một điểm dữ liệu&lt;/p></description></item><item><title>A Brief Introduction Of Logistic Regression</title><link>https://tienldn.online/blog/about-logistic-regression/</link><pubDate>Thu, 17 Jul 2025 00:00:00 +0000</pubDate><guid>https://tienldn.online/blog/about-logistic-regression/</guid><description>&lt;p>This article will show you&lt;/p>
&lt;h2 id="just-a-bit-of-math">Just a bit of math 
 
 
&lt;/h2>
&lt;h3 id="what-is-odd">What is Odd? 
 
 
&lt;/h3>
&lt;p>Odds are used to describe the chance of an event occurring. The odds are the &lt;em>ratios that compare the number of ways the event can occur with the number of ways the event cannot occurr&lt;/em>.&lt;/p>
$$
 Odds = \frac{p}{1 - p}
$$&lt;p>For example, if the probability of rain is 0.75 (or 75%), the probability of no rain is 0.25 (or 25%). The odds of rain are 0.75 / 0.25 = 3. This means it&amp;rsquo;s three times more likely to rain than not to rain.&lt;/p></description></item></channel></rss>